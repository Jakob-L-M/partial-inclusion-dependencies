\subsection{Partial Nary Candidate Generation}\label{sec:candidate_gen}
We now understand how \textit{SPIND} discovers unary pINDs. To discover nary pINDs, we need to generate candidates for the next layer using the data already collected from the current layer. An iterative process where progressively larger candidate sets are generated and verified follows the idea of an apriori-gen algorithm \cite{agrawal1994fast}. In related research, we find proposals that only use the most recent layer to generate the candidate set for the next layer \cite{papenbrock2015divide}. We will propose a refined version that significantly reduces the number of false candidates that need to be validated.

As proven, pINDs respect projection (see Section \ref{subsec:pIND_props}). For any pIND of size $n$, all subsets of that pIND must also be valid. This property has not been used to its full potential by past research. An adjusted version for improved candidate generation needs to follow the four rules below. Given two not necessarily different relational schema $R_a$ and $R_b$ with valid (n-1)-ary attributes $X \subseteq_\rho Y$ where $X \subset R_a, Y \subset R_b$ and valid unary attributes $A \subseteq_\rho B$ where $A \in R_a, B \in R_b$ a valid nary candidate $XA \subseteq_\rho YB$ is formed if and only if
\begin{itemize}
    \item[1)] The column index of $A$ is greater than the column index of all $x_i \in X$.
    \item[2)] $B$ is not contained in $Y$.
    \item[3)] All (n-1)-ary pINDs $R_a[(X \setminus X_i)A] \subseteq_\rho R_b[(Y \setminus Y_i)B] : i \in (1, \dots, n-1)$ must be valid.
    \item[4)] If $R_a$ and $R_b$ are the same scheme, then $X$, $A$, $Y$ and $B$ need to be pairwise disjoint.
\end{itemize}

In related work $B$ is required to be non-empty \cite{papenbrock2015divide}, a requirement that is logical when considering \textit{NULL} as a subset (see Section \ref{sec:null_subset}). \textit{SPIND} presents different perspectives on \textit{NULL} values, allowing all \textit{NULL} attributes to gain importance. As a result, the requirement for $B$ to be nonempty is removed. Applying the subset check (condition 3) is only explicitly required when producing candidates for the third layer or beyond. Unary candidates are easily created using all available columns, and the second layer consists of a combination of two unary pINDs, which directly means that all subsets must be valid.

\subsection{Serializing Nary Tuples.}\label{subsec:nary-strings}
Our unary discovery is based on strategies that are based on hashing and value comparison (e.g., sorting). By default tuples are a non-hashable type. We could implement custom comparison and hash functions for tuples. But this would require us to use a different procedure for unary and nary discovery, even if they practically do the same. Using a string representation of tuples instead enables us to use the unary procedures for nary pIND discovery, creating a simpler algorithmic structure. \textit{BINDER} \cite{papenbrock2015divide} also uses this strategy, where the values contained in some multidimensional tuple are concatenated using "\#" as a separator. The tuple \textit{("Marburg", "35037", "06421")} is transformed to the string "\textit{Marburg\#35037\#06421}". Concatenating values in this way can produce incorrect results if some of the tuple values contain the concatenation string. Trying to find a string that is not contained in any value of the data set imposes a new problem of significant complexity. To solve this in a mathematical sense, we are searching for a injective transformation $f: T \rightarrow S$ from the space of all string tuples to the space of all strings. The function $f$ accepts a tuple $t \in T$ consisting of strings $t = (s_1, ..., s_k)$ and creates a single string. The function used by \textit{BINDER} is not injective since the tuples $(1\#1, 1)$ and $(1, 1\#1)$ will produce the same string. Although this proves to be highly unlikely in real data sets, we should still eliminate this point of failure.

Our proposal function will take a $k$ dimensional tuple and first conduct a length encoding for the first $k-1$ values. These lengths are concatenated using ":", but any non-numerical character would work here. We mark the end of the length encoding using "|", again the precise choice of that character is not important. After the length encoding all values are concatenated without using a delimiter. The two tuples from before would be transformed to $("1\#1", "1") \rightarrow "3|1\#11"$ and $("1", "1\#1") \rightarrow "1|11\#1"$. Algorithm \ref{alg:string_transformation} displays the implementation of the described steps. There, lines 1 and 2 catch the unary case, for which we can skip the extra efforts. Our proposal is indeed injective. We need to make sure that every input tuple to our function maps to a distinct output. We will construct the inverse function $f^{-1}$ and show that the chain $f^{-1} \circ f$ is the identity function of $T$. Our inverse function will first search for the first occurrence of "|" which marks the end of the length encoding. The second part will then be split on the basis of the length information to extract the inputs.
Given a $k$-dimensional tuple of strings $(s_1, \dots, s_k)$, $f$ produces the string "$len(s_1)$:$len(s_2)$:\dots:$len(s_{k-1})$|$s_1 s_2 \dots s_k$". The inverse function $f^{-1}$ cuts the second part in the correct indices to reproduce the tuple $(s_1, \dots, s_k)$.

\begin{algorithm}[hbt!]
    \caption{N-ary Attribute String Creation}\label{alg:string_transformation}
    \KwInput{\textit{attributeValues}: The list of string values}
    \KwOutput{A String representation of all attribute values}

    \If{attributeValues.length == 1}{
        \Return \textit{attributeValues}[1]
    }

    representation = "" \\
    \tcc{Create the length encoding}
    \For{index \textbf{in} 1, \dots, attributeValues.length - 1}{
        representation.append(attributeValues[index].length) \\
        representation.append(":")
    }
    representation.append("|") \\
    \tcc{Append the actual values}
    \For{value \textbf{in} attributeValues}{
        representation.append(value)
    }
    \Return representation
\end{algorithm}