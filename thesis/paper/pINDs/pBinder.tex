\subsection{Partial BINDER}
\textit{BINDER} is a IND discovery Algorithm which uses a divide and conquer approach to efficiently find unary and nary INDs\cite{papenbrock2015divide}. It was shown that \textit{BINDER} outperforms other exact, non-distributed state-of-the-art algorithms in both unary and nary settings \cite{dursch2019inclusion}. Due to its strong performance, we also offer a adapted version of \textit{BINDER} which can handle partial IND discovery called \textit{pBINDER}.

\subsubsection{\textbf{Existing Code.}}
The original \textit{BINDER} source code was provided by the authors and will be used as a second point of references next to \textit{SPIDER}. Structurally the original source code poses challenges which motivated the effort of a rewrite which clearer classes and better documentation. In essence \textit{pBINDER} is almost equal to \textit{BINDER} up to newer libraries, refactoring and the following validation changes. 

\subsubsection{\textbf{Validation Adjustments.}}
The Validator of \textit{BINDER} handles the pruning of IND candidates. Initially the algorithm assumes, that all candidates are valid. Whenever we find a conflicting value, meaning a value which is present in the depended side but not in the referenced side of a candidate, the validator removes the given candidate. To consider partial INDs we need to expand \textit{BINDER} such that the validator keeps track of the number of violations and only removes a candidate, if more violations than a given threshold occurred. Algorithm \ref{alg:BINDER_prune} shows to proposed adjustments to the candidate pruning. The candidate violations are initialized analog to the initialization of \textit{SPIDER}.

Note that \textit{pBINDER} only supports a \textit{duplicateAware} setting. The concept and efficiency of \textit{BINDER} lies in the divide and conquer approach. The attributes are split into buckets using hash functions, such that the first bucket of each attribute maps the same subspace of values, e.g. there are $n$ buckets and we choose $hashCode \% n$ as the separation function. During the validation, the buckets are iterated in some order. At some point of the validation, we might already know, that the attribute is no longer included in any candidate. Loading the bucket now would be a waste of compute resources. Therefor we precisely skip these buckets. While this is great in a computational sense, \textit{BINDER} has no way of counting the number of distinct values, if not all buckets are loaded, especially if we would like to know the number of distinct values before the validation starts. Implementing \textit{duplicateUnaware} pIND discovery into \textit{pBINDER} would divert the algorithm too much from the original algorithm too a point where discussing the newly introduced complexity of pIND discovery would be unreasonable.

\begin{algorithm}
    \caption{Adjusted BINDER candidate pruning}\label{alg:BINDER_prune}
    \KwInput{value, valueGroup, pINDCandidates}
    \For{attribute in valueGroup} {
        occurrences = attribute.getOccurrences(value) \\
        \For{candidate in pINDCandidates} {
            \If{candidate.dependant $\not =$ attribute} { 
                \textbf{continue}
            }
            \If{candidate.reference $\in$ valueGroup} {
                \textbf{continue}
            }
            candidate.violations -= occurrences \\
            \If{candidate.violations $<$ 0} {
                remove candidate
            }
        }
    }
\end{algorithm}




% TODO test performance of rewrite and original
