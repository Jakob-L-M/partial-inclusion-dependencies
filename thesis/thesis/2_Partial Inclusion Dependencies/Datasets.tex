To understand the performance of the proposed algorithms it is crucial to perform testing on a variety of data sets. For this purpose we will gather some real word data sets. Further we will create synthetic data sets that aim on edge cases to see if the performance is strongly dependent on structural assumptions.

\subsection{Real World Data Sets}
There are many sources for csv or tsv files online. I have decided to gather data from the US Government\footnote{\href{https://data.gov}{data.gov}}, the European Union \footnote{\href{https://data.europe.eu}{data.europe.eu}}, Kaggle, \footnote{\href{https://kaggle.com}{Kaggle.com}}, Musicbrainz \footnote{\href{https://musicbrainz.org/}{musicbrainz.org}}, 

% TODO: MORE

\subsection{Synthetic Data Sets}
To test certain edge cases of the proposed algorithms, we will construct various edge case data sets. The \textit{SameSame} data set consists of 25 attributes and 250.000 records. Each attribute carries the numbers 1 to 250.000 in the natural order. This means every attribute is a (partial) inclusion dependency of every other attribute. The same obviously also holds for combinations of columns.

% TODO calculate INDs

