\chapter{Conclusion}
Our proposed algorithm \textit{SPIND} is able to overcome the inconveniences of past algorithms while outperforming them significantly. Our findings are possible by using the changes in hardware and adapting algorithmic decisions on them. We demonstrate that I/O operations are no longer a significant bottleneck and highlight the importance of leveraging the multi-threaded capabilities of modern CPUs.

We recognize that there are unresolved topics that future research can explore. A central observation in complex datasets with a large number of nary pINDs is that the generated candidates eventually become equal or almost equal to the valid pINDs of some layer. An idea would be to jump a few layers ahead if such a thing happens, since it strongly hints towards the existence of pINDs in a (much) deeper layer. In \textit{ACNH} we find that from the seventh to the twelve layer the generated candidates were always all valid. De Marchi et al. have previously examined this type of generation \cite{de2003zigzag}, but it is necessary to determine whether this approach generally yields better performance or if it is only effective for specific data sets. 

% An additional optimization that appears to be promising involves encoding the attribute identifiers and their occurrences (integers and longs) into four- and eight-byte blocks. This method could significantly reduce the file size, thereby potentially enhancing I/O speeds considerably.